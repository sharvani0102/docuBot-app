# ğŸ“„ DocuBot App

DocuBot is a **PDF-based conversational chatbot** built using **Streamlit** and **LangChain**.  
It allows users to upload PDF documents and ask questions, with answers generated directly from the document content using **Retrieval-Augmented Generation (RAG)**.

---

## ğŸš€ Features

- ğŸ“‚ Upload one or multiple PDF files
- ğŸ” Semantic search using vector embeddings
- ğŸ¤– Conversational Q&A with memory
- ğŸ’¬ Chat-style interface with typing animation
- ğŸ’¾ Persistent vector database using Chroma
- âš¡ Fast inference powered by **Groq (LLaMA 3)**

---

## ğŸ§± Tech Stack

- **Frontend:** Streamlit
- **LLM:** Groq (LLaMA3-8b-8192)
- **Framework:** LangChain
- **Vector Store:** ChromaDB
- **Embeddings:** OpenAI Embeddings
- **PDF Loader:** PyPDFLoader
- **Memory:** ConversationBufferMemory

---

## ğŸ“ Project Structure

ğŸ“¦ docuBot-app
â”œâ”€â”€ .devcontainer/ # Dev container configuration
â”œâ”€â”€ .github/ # GitHub workflows/configs
â”œâ”€â”€ .gitignore # Git ignore rules
â”œâ”€â”€ LICENSE # Apache-2.0 License
â”œâ”€â”€ README.md # Project documentation
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ streamlit_app.py # Main Streamlit application

---

## ğŸ“¦ Installation

### 1ï¸âƒ£ Clone the Repository
bash
git clone https://github.com/sharvani0102/docuBot-app.git
cd docuBot-app 

2ï¸âƒ£ Create a Virtual Environment (Recommended)
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

ğŸ” API Keys Configuration
Create a file at:
.streamlit/secrets.toml
Add your Groq API key:
[groq_api_key]
my_key = "YOUR_GROQ_API_KEY"
âš ï¸ This project also uses OpenAI Embeddings, so ensure your OpenAI credentials are properly configured.

â–¶ï¸ Running the Application
streamlit run streamlit_app.py

Once the app launches:
Upload one or more PDF files
Wait for the documents to be indexed
Ask questions in the chat input
Receive answers grounded in the PDF content

How It Works
Uploaded PDFs are saved locally
Documents are split into overlapping text chunks
Text chunks are embedded using OpenAI embeddings
Embeddings are stored in a Chroma vector database
User queries retrieve relevant chunks
Groq LLaMA 3 generates answers using retrieved context and chat history


ğŸ“Œ Future Enhancements
Source citation in responses
PDF deletion and re-indexing
Streaming token-level responses
Streamlit Cloud deployment
Authentication for private documents

ğŸ“œ License
This project is licensed under the Apache License 2.0.
See the LICENSE file for more details.




